{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ047plKQAI5"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/TUIlmenauAMS/Videocoding/blob/main/LecturesJupterNotebooks/Lecture4/Lecture4.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "<font size=\"8\" color =\"Brown\"><center>\n",
        "# Lecture 4, Video Coding, Irrelevance Reduction, Transforms\n",
        "        \n",
        "<center></font>\n",
        "<br>\n",
        "\n",
        "<p style=\"line-height:1.5\">\n",
        "<font size=\"6\">We saw: we have many more light sensitive sensors (rods, cones) than we have optical nerve fibers into the brain. This means the retina does some pre-processing to obtain a compression. It does this by spatial filtering. The basic system can be seen in the following picture:<br>\n",
        "\n",
        "![Lecture4-1.PNG](https://github.com/TUIlmenauAMS/Videocoding/blob/main/LecturesJupterNotebooks/Lecture4/Img-Lecture4/Lecture4-1.PNG?raw=1)\n",
        "<br>\n",
        "**Weber's Law:**  $ \\frac{\\Delta w} {w} = konst $<br><br>\n",
        "- states that the ratio of the increment threshold to the background intensity is a constant.<br>\n",
        "- measurement of increment thresholds on various intensity backgrounds, the thresholds increase in proportion to the background. <br>\n",
        "<br>\n",
        "The weights are part of what is called **“receptive fields”** in the retina, and they are comparable to our filter kernel. The resulting spatial frequency response of this system is the co-called Contrast Sensitivity function of the eye:\n",
        "\n",
        "![Lecture4-2.PNG](https://github.com/TUIlmenauAMS/Videocoding/blob/main/LecturesJupterNotebooks/Lecture4/Img-Lecture4/Lecture4-2.PNG?raw=1)\n",
        "\n",
        "The CSF measures the sensitivity of the eye for different spatial frequencies.<br>\n",
        "The contrast is defined as follows: The maximum light intensity is $L_{max}$, and the minimum intensity $L_{min}$. Then the so-called “Michaelson Contrast” is<br>\n",
        "$$\n",
        "c=\\frac{ L_{max}-L_{min} } { L_{max}+L_{min} }\n",
        "$$\n",
        "The contrast sensitivity has $1/c$ on its vertical axis.\n",
        "<br><br>\n",
        "The following shows a sketch to visualize spatial frequencies:\n",
        "\n",
        "<br>\n",
        "\n",
        "![Lecture4-3.PNG](https://github.com/TUIlmenauAMS/Videocoding/blob/main/LecturesJupterNotebooks/Lecture4/Img-Lecture4/Lecture4-3.PNG?raw=1)\n",
        "<br>\n",
        "An example for an image with different pure spatial frequencies with different contrasts can be seen in following picture. On the left hand side are low spatial frequencies, right are high frequencies. On the lower side are high contrasts, on the higher side are low contrasts:<br><br>\n",
        "\n",
        "![Lecture4-4.PNG](https://github.com/TUIlmenauAMS/Videocoding/blob/main/LecturesJupterNotebooks/Lecture4/Img-Lecture4/Lecture4-4.PNG?raw=1)\n",
        "<br>\n",
        "Observe: cameras also have this type of transfer function, but there it is called “Modulation Transfer Function” (MTF). This type of function is independent on the type of imaging sensor, for instance you can also have a MTF for ultra sound images, or X-ray images. Spatial frequencies have no time unit in them, just spatial units (degree).<br><br>\n",
        "\n",
        "The eye has different CSF for luminance and chrominance (color), mainly because of the different number of sensors. It also has a limited temporal speed. Both can be seen in following picture:<br>\n",
        "<br>\n",
        "![Lecture4-5.PNG](https://github.com/TUIlmenauAMS/Videocoding/blob/main/LecturesJupterNotebooks/Lecture4/Img-Lecture4/Lecture4-5.PNG?raw=1)\n",
        "<br>\n",
        "![Lecture4-6.PNG](https://github.com/TUIlmenauAMS/Videocoding/blob/main/LecturesJupterNotebooks/Lecture4/Img-Lecture4/Lecture4-6.PNG?raw=1)\n",
        "<br>\n",
        "These measurements where made with test subjects, which tested which patterns can be seen. Hence this most likely reflects the properties in the area of the sharpest vision, the fovea.\n",
        "\n",
        "<br><br><br>\n",
        "\n",
        "How can these effects be used in video coding?\n",
        "<br><br><br>\n",
        "\n",
        "Since the eye has different sensitivities for different spatial frequencies, we need to decompose our images or frames into subbands with different spatial frequencies and quantize them with an accuracy which is suitable to the sensitivity for the eye at the spatial frequency of the subband.\n",
        "<br><br>\n",
        "We already saw that we can obtain a frequency decomposition of our frames using the 2D DFT. But this is not the only method, and as we will see not the optimum method for image and video coding. The 2D DFT is a special case of a **block transform**, which in turn is a special case of a **filter bank**  with sampling.\n",
        "<br>\n",
        "\n",
        "</font></p>    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV-TWwBMQAJL"
      },
      "source": [
        "<font size=\"8\" color =\"Brown\"><center>\n",
        "## Transform Coding\n",
        "\n",
        "\n",
        "<center></font>\n",
        "<br>\n",
        "\n",
        "<p style=\"line-height:1.5\">\n",
        "<font size=\"6\">\n",
        "After motion compensation (in the block “image encoder” which we will still see) we **usually apply the DCT to** blocks of the prediction error image, or directly on the image.<br>\n",
        "We apply transform coding to our image, or the prediction error image, with the goal to **minimize the number of bits** needed for transmitting or storing this image. Transform coding can be viewed as being part of the redundancy reduction and also the **irrelevance reduction**. In this way it is an addition to the predictive coding (e.g. with motion compensation), or can also be used as an alternative. But unlike the predictive coding, for transform coding we can also use psycho-optical effects, because we can take advantage of the different sensitivities of our eye to different spacial frequencies, as signified by the **Contrast Sensitivity Function** of the eye. This is possible because the transform delivers different subbands at different spacial frequencies, which we can then be encoded with adapted accuracy (adapted to the CSF).<br>\n",
        "So far we have mainly redundancy reduction with our predictive coding, and now we can also use more **irrelevance reduction** in this way.<br><br>\n",
        "The basic principle of applying transforms to our images or prediction error images is, to first subdivide our image into blocks (for instance size 8x8 pixels), and then apply our transform to each block. Usually we use a so-called separable transform (meaning it is defined only for 1 dimension, like a DFT or a DCT), which is then applied first to one dimension (for instance the rows). The result is then used to apply the transform to the other dimension, like the columns.\n",
        "<br><br>\n",
        "</font></p>    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lg4y8r1QAJN"
      },
      "source": [
        "<font size=\"8\" color =\"Brown\"><center>\n",
        "## Equivalence of Transforms and Critical Sampled Filter Banks\n",
        "<center></font>\n",
        "<br>\n",
        "<p style=\"line-height:1.5\">\n",
        "<font size=\"6\">\n",
        "    \n",
        "A **critical sampled filter bank** is a filter bank, where the **downsampling factor is identical to the number of subbands**. This was the case for instance in 2 band decompostion of an image. We have 2 bands, and also a downsampling factor of 2. How does the transform and its connection to filter banks look mathematically?\n",
        "\n",
        "</font></p>    \n",
        "\n",
        "<font size=\"8\" color =\"Brown\"><center>\n",
        "## Transforms\n",
        "        \n",
        "<center></font>\n",
        "<br>\n",
        "\n",
        "<p style=\"line-height:1.5\">\n",
        "<font size=\"6\">\n",
        "    \n",
        "The  DFT of a block of signal x (for instance a row of our image block), which starts at sample $x(mN)$, and has length N, is defined as <br>\n",
        "$$\n",
        "X_m(k) =\\sum_{n= 0} ^ {N-1} x(mN+n) e ^{-j 2\\frac{\\pi} { N}.k.n}\n",
        "$$\n",
        "<br>\n",
        "Now we can rewrite the  DFT as a matrix multiplication with the matrix $T$ with the elements,<br>\n",
        "$$\n",
        "\\boldsymbol {T} _{n,k}=e ^{-j \\frac{2 \\pi}  {N}.n.k}\n",
        "$$\n",
        "<br>\n",
        "n is the time and row index, and k is the frequency and column index. Using the block vector<br>\n",
        "$$\n",
        "\\boldsymbol x (m)=[x(mN),x(mN+1), ..., x(mN+N-1)]\n",
        "$$  (eq:1)<br>\n",
        "we can rewrite the DFT of block m as a matrix multiplication,<br>\n",
        "$$\n",
        "\\boldsymbol y (m) = \\boldsymbol x (m). \\boldsymbol T\n",
        "$$\n",
        "<br>\n",
        "This is the matrix formulation of the DFT\n",
        "<br><br>\n",
        "Take this **transform matrix** $\\boldsymbol T$, which contains the coefficients of our transform (for instance a DCT matrix, where each column contains the coefficients of a different subband filter), and a **block of the image** $\\boldsymbol x$ , for instance containg the 8x8 pixels (we use boldface letters for matrices and vectors). <br>\n",
        "If we want to apply this transform to the **rows** of the image, we have to multiply the transform matrix $\\boldsymbol T$ **from the right** $\\boldsymbol x.\\boldsymbol T$, (each row of $\\boldsymbol x$ is multiplied by $\\boldsymbol T$ ). Each **column** of $\\boldsymbol T$ can now be seen as a **different filter** for a subband. Assume we have subbands $N$, then we have filters with impulse responses $h_k(n)$, where k is the subband index $(k=0,...,N-1)$, and n is the time or space index of the impulse response ($n=0,...,N-1$, because we have a **square matrix** for **invertibility** or perfect reconstruction, which limits the length of our filters to N). Hence our matrix has the form<br>\n",
        "\n",
        "![Lecture4-7.PNG](https://github.com/TUIlmenauAMS/Videocoding/blob/main/LecturesJupterNotebooks/Lecture4/Img-Lecture4/Lecture4-7.PNG?raw=1)<br>\n",
        "\n",
        "Observe that the impulse responses appear in **reverse order!**\n",
        "\n",
        "<br><br>\n",
        "\n",
        "\n",
        "If we multiply this matrix from the right side on our block $\\boldsymbol x$, we multply each row of x with each column of $\\boldsymbol T$. This vector multiplication of one signal row with one colmn of the transform (containing the impulse response of one filter) is **mathematically identical to the convolution** of the signal with this filter, but where we only obtain one value of this convolution (we get one value for each vector multiplication of one row of x with one column of $\\boldsymbol T$). Because we only get one value for each subband for one block (instead of for each sample), we already have (implicitly) included the **downsampling** of the equivalent filter bank. In this way we get one value for each row of $\\boldsymbol x$ and each subband of $\\boldsymbol T$, for a total of NxN values. This can also be seen if we look at the matrix multiplication: we obtain a square result matrix of size NxN.\n",
        "<br><br>\n",
        "The following image depicts a 1-D filter bank, for instance along the rows, with **critical sampling** (down sampling rate equal to the number of subbands):\n",
        "with<br>\n",
        "\n",
        "\n",
        "![Lecture4-8.PNG](https://github.com/TUIlmenauAMS/Videocoding/blob/main/LecturesJupterNotebooks/Lecture4/Img-Lecture4/Lecture4-8.PNG?raw=1)<br>\n",
        "$$\n",
        "y_k(m)=\\sum _{n=0} ^\\infty x(mN-n) .h_k(n)\n",
        "$$\n",
        "(m is the block index). Observe that this is a **convolution** equation, except for the factor of N behind the block index m. This factor results from the **downsampling** with the factor N.\n",
        "\n",
        "<br><br>\n",
        "\n",
        "Compare this with the transform equation from above,\n",
        "$$\n",
        "X_m(k) =\\sum _{n= 0} ^{N-1} x(mN+n) e ^{-j \\frac{2\\pi}{ N }.k.n}\n",
        "$$\n",
        "<br>\n",
        "for the comparison we assume that the filter $h_k(n)$ is only of length N, hence the convolution sum for $y_k(m)$ only goes up to N-1. Then we replace the index n in the transform equation by N-1-n'. We get<br>\n",
        "$$\n",
        "X_m( k )=y_k( m )= \\sum _ { n'=0 } ^{ N-1 } x( mN+N-1-n' ) .e^{ j \\frac{2 \\pi } {N} .(N-1-n') . k }\n",
        "$$\n",
        "<br>\n",
        "This now corresonds to the convolution equation for $y_k(m)$ but with a shift of N-1 samples in the signal x, and with the **equivalent impulse response** of\n",
        "\n",
        "$$\n",
        "h_k( n )=e^{ j 2 \\frac{\\pi} { N} .(N-1-n) .k }\n",
        "$$\n",
        "<br>\n",
        "\n",
        "This shows why the analysis transform matrix contains the impulse responses of the equivalent filters, but in **reverse order**\n",
        "<br><br\n",
        "This approach now shows, that applying the transform is identical to a filter bank with critical sampling, but with the **restriction** that the filters have to be of **length N** (otherwise we would not have an invertible square matrix). This means the **transform** is a **special case of a filter bank**  with critical sampling.\n",
        "\n",
        "<br><br>\n",
        "\n",
        "So for the rows we get<br>\n",
        "$$\\boldsymbol x'=\\boldsymbol x .  \\boldsymbol T$$\n",
        "We still need to apply our transform to the **columns**. To obtain this, we simply multiply the transpose of our transform matrix from the left hand side,<br>\n",
        "$$\\boldsymbol y := \\boldsymbol T^T . \\boldsymbol x'$$\n",
        "or, taking both steps together,\n",
        "<br>\n",
        "$$\\boldsymbol y = \\boldsymbol T ^T .\\boldsymbol x . \\boldsymbol T$$\n",
        "$y$ now contains the frequency domain coefficients of our image block $x$.\n",
        "Writing the transform as the matrix multiplication has the big advantage, that we can easily take the inverse transform for the **decoder**,<br>\n",
        "$$\n",
        "\\boldsymbol x = \\boldsymbol T^{-T} . \\boldsymbol y.\\boldsymbol T^{-1}\n",
        "$$\n",
        "where $.^{-T}$ is the inverse of the transpose. In this way we get easily the perfect reconstruction in the decoder.<br>\n",
        "**Example:** The DCT Type 2 is defined as\n",
        "\n",
        "\n",
        "<br><br>\n",
        "\n",
        "$$\n",
        "T_{ n,k }=\\frac{1 }{ \\sqrt N }.  cos( \\frac{\\pi }{N} .(n+0.5). k )$$\n",
        "for $n,k=0,...,N-1.$\n",
        "</font></p>    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYsqmFmaQAJQ"
      },
      "source": [
        "<font size=\"8\" color =\"Brown\"><center>\n",
        "## Python Example:\n",
        "        \n",
        "<center></font>\n",
        "<br>\n",
        "\n",
        "<p style=\"line-height:1.5\">\n",
        "<font size=\"6\">Take a 4x4 block of an image, for instance a part of a somewhat dark and even background:\n",
        "\n",
        "</font></p>    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-c5OAcTQAJT",
        "outputId": "d17b528d-2bf0-4a4a-ceed-12c6fb4feb27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.3, 0.3, 0.3, 0.3],\n",
              "       [0.3, 0.3, 0.3, 0.3],\n",
              "       [0.3, 0.3, 0.3, 0.3],\n",
              "       [0.3, 0.3, 0.3, 0.3]])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "x=0.3*np.ones((4,4))\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKZ8i7WfQAJZ"
      },
      "source": [
        "\n",
        "<p style=\"line-height:1.5\">\n",
        "<font size=\"6\">\n",
        "Now transform this block x. First compute the transform matrix $\\boldsymbol T$, which in this example is a so-called DCT type 2. First we obtain the transform matrix T by applying the DCT to the identity matrix I (norm=’ortho’ includes the square root term):\n",
        "</font></p>    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaCRNQRWQAJb",
        "outputId": "f402b3b3-d2d6-4dd5-f8f0-baafe8a38f16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1.]])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import scipy.fftpack\n",
        "I=np.eye(4)\n",
        "I\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxUTdoGFQAJd",
        "outputId": "c574fc91-0b04-4181-acd5-bde9a43a653a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.5       ,  0.65328148,  0.5       ,  0.27059805],\n",
              "       [ 0.5       ,  0.27059805, -0.5       , -0.65328148],\n",
              "       [ 0.5       , -0.27059805, -0.5       ,  0.65328148],\n",
              "       [ 0.5       , -0.65328148,  0.5       , -0.27059805]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "T=scipy.fftpack.dct(I,norm='ortho')\n",
        "T\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tJ-qdSoQAJg"
      },
      "source": [
        "\n",
        "<p style=\"line-height:1.5\">\n",
        "<font size=\"6\">\n",
        "    \n",
        "Here we can see that each column represents a filter. <br>\n",
        "For instance our filter impulse response (the coefficients) for the lowest subband, (including flipping it up-down) is\n",
        "    \n",
        "</font></p>    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ax--QqpbQAJh",
        "outputId": "8e85ca3a-95f4-4ec6-a646-0a897bafa856"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.5, 0.5, 0.5, 0.5])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "h0=np.flipud(T[:,0])\n",
        "h0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QCIapznQAJj"
      },
      "source": [
        "<p style=\"line-height:1.5\">\n",
        "<font size=\"6\">Now we can transform our block to obtain our 2-dimensional subband values ,\n",
        "</font></p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjmawcMaQAJk",
        "outputId": "4ce6bea8-7616-4b61-f68b-9ab796dd4519"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.2, 0. , 0. , 0. ],\n",
              "       [0. , 0. , 0. , 0. ],\n",
              "       [0. , 0. , 0. , 0. ],\n",
              "       [0. , 0. , 0. , 0. ]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y=np.dot(np.dot(np.transpose(T),x),T)\n",
        "y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW2ETmpiQAJm"
      },
      "source": [
        "<p style=\"line-height:1.5\">\n",
        "<font size=\"6\">\n",
        "    \n",
        "**Observe:** We have only **1 large value,** the 1.2, in the upper, left hand corner. This corresponds to filter $h_0(0)$ horizontally and vertically. The rest of the coefficients is zero. For natural images, the DCT usually has this effect, that the large values appear in the upper, left hand corner, and the rest of the values are much smaller. This property is also called **\"energy compaction\"**, and is used to reduce the bit rate, by taking advantage of redundancies in our signal, the image block. For instance, many consecutive zeros can be efficiently and easily encoded using the run-length coding (an escape code, followed by the value and the number of repetitions).\n",
        "</font></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEiSZbJ7QAJn"
      },
      "source": [
        "<font size=\"8\" color =\"Brown\"><center>\n",
        "## Python Video Example\n",
        "        \n",
        "<center></font>\n",
        "<br>\n",
        "\n",
        "<p style=\"line-height:1.5\">\n",
        "<font size=\"6\">The following example show a live video where the frames are DCT2 transformed, and the magnitude of the DCT coefficients displayed:\n",
        "You can also run this example with following command in terminal.\n",
        "\n",
        "```\n",
        "    python videorecdctdisp.py\n",
        "```\n",
        "</font></p>    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORmX1w61QAJo"
      },
      "outputs": [],
      "source": [
        "#Program to capture a video from the default camera (0), compute the 2D DCT Type 2\n",
        "#on the Green component, take the magnitude (phase) and display it live on the screen\n",
        "#Gerald Schuller, Nov. 2014\n",
        "import cv2\n",
        "import numpy as np\n",
        "import scipy.fftpack as sft\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while(True):\n",
        "    # Capture frame-by-frame\n",
        "    [retval, frame] = cap.read()\n",
        "\n",
        "    #compute magnitude of 2D DCT of green component\n",
        "    #by applying the DCT first along the rows and the along the columns,\n",
        "    #with suitable normalization for the display:\n",
        "    frame=sft.dct(frame[:,:,1]/255.0,axis=1,norm='ortho')\n",
        "    frame=np.abs(sft.dct(frame,axis=0,norm='ortho'))\n",
        "    #angle/phase:\n",
        "    #frame=(3.14+np.angle(np.fft.fft2(frame[:,:,1]/255.0)))/6.28\n",
        "    # Display the resulting frame\n",
        "    cv2.imshow('Magnitude of 2D - DCT Type 2 of the Video',frame)\n",
        "    #Keep window open until key 'q' is pressed:\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "# When everything done, release the capture\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iu-D0fP_QAJp"
      },
      "source": [
        "<p style=\"line-height:1.5\">\n",
        "<font size=\"6\">\n",
        "**Observe:** Bright points, corresponding to **large coefficients**, mostly appear in the **upper left hand corner**, and no longer in all 4 corners as with the DFT. We no longer have the symmetry around the center of the frame. Since we now no longer have 2 copies of our spectrum, the 2D DCT uses our pixels to **finer describe** this one copy of our 2D-spectrum.<br>\n",
        "If we hold a **fine pattern** in front of the camera, **larger coefficients** also appear **towards the center** of the 2D spectrum, depending on the pattern, as with the DFT.<br><br>\n",
        "\n",
        "The **next example** shows what happens if we set most of the higher frequency DCT coefficients to zero, and then apply the inverse DCT to obtain our frame back:<br><br>\n",
        "\n",
        "```\n",
        "    python videorecdct0idctdisp.py\n",
        "```\n",
        "</font></p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOxERGA6QAJp",
        "outputId": "a2dbaad8-454a-40d9-8104-145cb9f7770b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "480 640\n"
          ]
        }
      ],
      "source": [
        "#Program to capture a video from the default camera (0), compute the 2D FFT\n",
        "#on the Green component, take the magnitude (phase) and display it live on the screen\n",
        "#apply a 2D DCT , low pass filter, and iverse transform.\n",
        "#Gerald Schuller, Nov. 2014\n",
        "import cv2\n",
        "import numpy as np\n",
        "import scipy.fftpack as sft\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "#Get size of frame:\n",
        "[retval, frame] = cap.read()\n",
        "[r,c,d]=frame.shape\n",
        "print(r,c)\n",
        "\n",
        "#Mask to set to zero the 3/4 highest frequencies,\n",
        "#only kep the 1/4 lowest frequencies in each direction for the DCT,\n",
        "#because of the DCT no longer symmetric about the center:\n",
        "\n",
        "#For rows:\n",
        "Mr=np.ones((r,1))\n",
        "Mr[int(r/4.0):r,0]=np.zeros(int(3.0/4.0*r))\n",
        "#For columns:\n",
        "Mc=np.ones((1,c))\n",
        "Mc[0,int(c/4.0):c]=np.zeros(int(3.0/4.0*c));\n",
        "#Together:\n",
        "M=np.dot(Mr,Mc)\n",
        "\n",
        "while(True):\n",
        "    # Capture frame-by-frame\n",
        "    [retval, frame] = cap.read()\n",
        "    cv2.imshow('Original Video, Gruen Komponente',frame[:,:,1])\n",
        "\n",
        "    #compute magnitude of 2D DCT of green component\n",
        "    #with suitable normalization for the display,\n",
        "    #with norm='ortho' for \"energy conservation\" in the subbands and for\n",
        "    #invertibiltity without factor:\n",
        "    X=sft.dct(frame[:,:,1]/255.0,axis=1,norm='ortho')\n",
        "    X=sft.dct(X,axis=0,norm='ortho')\n",
        "    #Set to zero the 7/8 highest spacial frequencies in each direction:\n",
        "    X=X*M\n",
        "    frame=np.abs(X)\n",
        "\n",
        "    # Display the resulting frame\n",
        "    cv2.imshow('2D-DCT with setting to zero the highest spatial frequencies',frame)\n",
        "    #Inverse 2D DCT:\n",
        "    X=sft.idct(X,axis=1,norm='ortho')\n",
        "    x=sft.idct(X,axis=0,norm='ortho')\n",
        "    cv2.imshow('Inverse 2D DCT without the highest spatial frequencies', x)\n",
        "\n",
        "    #Keep window open until key 'q' is pressed:\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "# When everything done, release the capture\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQrPEnlNQAJr"
      },
      "source": [
        "<p style=\"line-height:1.5\">\n",
        "<font size=\"6\">\n",
        "\n",
        "**Observe:** even though we set **most** of our DCT coefficients to **zero**, the reconstructed frame **still looks good**, just a little unsharp. This means this is a **powerful method to compress** our frames!\n",
        "<br><br><br>\n",
        "Example for applying the DCT- zero-setting of the high frequency coefficient- inverse DCT to **blocks of size 8x8 pixels:**\n",
        "<br>\n",
        "```\n",
        "python videorecdctblocks0idctdisp.py\n",
        "```\n",
        "</font></p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOhoMDf8QAJs",
        "outputId": "46df798e-e1c3-42bb-efd4-839677ef494a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "480 640\n"
          ]
        }
      ],
      "source": [
        "#Program to capture a video from the default camera (0), compute the 2D DCT\n",
        "#on the Green component, take the magnitude (phase) and display it live on the screen, divide the picture into blocks\n",
        "#of 8x8 pixels and apply a 2D DCT to each, low pass filter, and inverse transform.\n",
        "#Gerald Schuller, Nov. 2014\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import scipy.fftpack as sft\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "#Get size of frame:\n",
        "[retval, frame] = cap.read()\n",
        "[r,c,d]=frame.shape\n",
        "print(r,c)\n",
        "\n",
        "#Mask to set to zero the 3/4 highest frequencies,\n",
        "#only kep the 1/4 lowest frequencies in each direction for the 8x8 DCT,\n",
        "#because of the DCT no longer symmetric about the center:\n",
        "\n",
        "#For rows:\n",
        "Mr=np.ones(8)\n",
        "Mr[int(8/4.0):r]=np.zeros(int(3.0/4.0*8))\n",
        "#For columns:\n",
        "Mc=Mr;\n",
        "\n",
        "#Grid of 8x8 blocks:\n",
        "gc=np.zeros((1,c))\n",
        "gc[0,0:c:8]=np.ones(int(c/8))\n",
        "gr=np.zeros((r,1))\n",
        "gr[0:r:8,0]=np.ones(int(r/8))\n",
        "grid=np.ones((r,1))*gc+gr*np.ones((1,c))\n",
        "#print(grid[0:9,0:9])\n",
        "\n",
        "while(True):\n",
        "    # Capture frame-by-frame\n",
        "    [retval, frame] = cap.read()\n",
        "\n",
        "    cv2.imshow('Original Video, Green Component, with superimposed 8x8 grid',frame[:,:,1]/255.0+grid)\n",
        "    #cv2.imshow('Original Video, Gruen Komponente',frame[:,:,1])\n",
        "\n",
        "    #compute magnitude of 2D DCT of blocks of 8x8 pixels of the green component\n",
        "    #by first reshaping the image to width 8 and applying the 1D DCT all rows, then reshape it back,\n",
        "    #then transpose it, and again reshape it to width 8 and apply the 1D DCT to each row, reshape it back,\n",
        "    #and transpose it back.\n",
        "    #with norm='ortho' for \"energy conservation\" in the subbands and for\n",
        "    #invertibiltity without factor.\n",
        "\n",
        "    #First reshape green frame as frame with rows of width 8, (rows: order= 'C' ),\n",
        "    #and apply DCT to each row of length 8 of all blocks:\n",
        "    frame=np.reshape(frame[:,:,1],(-1,8), order='C')\n",
        "    X=sft.dct(frame/255.0,axis=1,norm='ortho')\n",
        "    #apply row filter to each row by matrix multiplication with Mr as a diagonal matrix from the right:\n",
        "    X=np.dot(X,np.diag(Mr))\n",
        "    #shape it back to original shape:\n",
        "    X=np.reshape(X,(-1,c), order='C')\n",
        "    #Shape frame with columns of hight 8 by using transposition .T:\n",
        "    X=np.reshape(X.T,(-1,8), order='C')\n",
        "    X=sft.dct(X,axis=1,norm='ortho')\n",
        "    #apply column filter to each row by matrix multiplication with Mc as a diagonal matrix from the right:\n",
        "    X=np.dot(X,np.diag(Mc))\n",
        "    #shape it back to original shape:\n",
        "    X=(np.reshape(X,(-1,r), order='C')).T\n",
        "    #Set to zero the 7/8 highest spacial frequencies in each direction:\n",
        "    #X=X*M\n",
        "    frame=np.abs(X)\n",
        "\n",
        "    # Display the resulting frame\n",
        "    cv2.imshow('2D-DCT with setting zero the highest spatial frequencies per 8x8 Block',frame)\n",
        "    #Inverse 2D DCT,\n",
        "    #Rows:\n",
        "    X=np.reshape(X,(-1,8), order='C')\n",
        "    X=sft.idct(X,axis=1,norm='ortho')\n",
        "    #shape it back to original shape:\n",
        "    X=np.reshape(X,(-1,c), order='C')\n",
        "    #Shape frame with columns of hight 8 (columns: order='F' convention):\n",
        "    X=np.reshape(X.T,(-1,8), order='C')\n",
        "    x=sft.idct(X,axis=1,norm='ortho')\n",
        "    #shape it back to original shape:\n",
        "    x=(np.reshape(x,(-1,r), order='C')).T\n",
        "\n",
        "    cv2.imshow('Inverse 2D DCT without the highest spatial frequencies', x)\n",
        "\n",
        "    #Keep window open until key 'q' is pressed:\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "# When everything done, release the capture\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gA3PQuyVQAJu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}