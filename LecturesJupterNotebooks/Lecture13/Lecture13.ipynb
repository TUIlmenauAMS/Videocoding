{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font size=\"8\" color =\"Brown\"><center>\n",
    "# H.264 Successor\n",
    " High Efficiency Video Coding (HEVC), H.265     \n",
    "<center></font>\n",
    "<br>\n",
    "\n",
    "<p style=\"line-height:1.5\">\n",
    "<font size=\"6\">HEVC or H.265 is the successor of H.264 in the MPEG\n",
    "standardization process.<br>\n",
    "There was a Call for Evidence on High Performance Video\n",
    "Coding in 2009, and the first JCT-VC for reviewing the\n",
    "submission for HEVC was held in April of 2010 in Dresden.\n",
    "(from: “Special Section on the Joint Call for Proposals on\n",
    "High Efficiency Video Coding (HEVC) Standardization,\n",
    "IEEE Transactions on Circuits and Systems for Video\n",
    "Technology, Dec. , 2010, by G. Sullivan et al. [1]).<br><br>\n",
    "   The **goals** of this standardization process:<br>\n",
    "Application for video sequences also for **higher resolutions**,\n",
    "in application areas like HDTV, Blu-Ray video, HD video on\n",
    "demand, internet delivery, or video for **mobile devices**.\n",
    "At the higher resolutions we can use more of the\n",
    "redundancies in our videos, and especially for videostreaming\n",
    "over mobile devices lower bit rates and limited\n",
    "complexity are important. These emerging applications are\n",
    "the target for the HEVC standardization.<br>\n",
    "The call for proposals specified video resolutions and\n",
    "maximum bit rates for the desired HEVC coder:<br>\n",
    "\n",
    "![Lecture13-1.PNG](Img-Lecture13\\Lecture13-1.PNG)   \n",
    "\n",
    "(from [1]) desired video formats and maximum bit rates for\n",
    "HEVC.<br><br>\n",
    "WVGA is “wide” VGA, with a resolution of 854x480 pixels\n",
    "or 800x280 pixels.<br>\n",
    "WQVGA is “wide quarter” VGA, with 416x240 pixels\n",
    "resolution. The different formats and their names can also be\n",
    "seen in the following picture:<br><br>\n",
    "\n",
    "![Lecture13-2.PNG](Img-Lecture13\\Lecture13-2.PNG)\n",
    "\n",
    "Ref: https://en.wikipedia.org/wiki/Super_video_graphics_array\n",
    "<br><br>\n",
    "In the table we can see that the target **format range is quite\n",
    "wide**, ranging from quarter WVGA with 416x240 pixels over\n",
    "HD720 and HD1080 up to a resolution of 2560x1600 at the\n",
    "high end (WQXGA in above picture), cropped from 4K x 2K\n",
    "Ultra HD format (UHD).<br><br>\n",
    "The bit rates also have a wide range, from 256 kb/s at\n",
    "WQVGA and HD720 formats, up to 14 Mb/s at the highest\n",
    "resolution of 2560x1600 pixels.<br>\n",
    "There were several **proposals** for this coder, introducing new\n",
    "tools to the video coding process. One interesting proposal is\n",
    "from Fraunhofer Heinrich Hertz Institute in Berlin, another\n",
    "from a consortium of Tandberg, Nokia, and Ericsson.<br>\n",
    "A few interesting **tools** are as follows:<br>\n",
    "-A flexible blocking structure, called nested quadtree\n",
    "structure, where we have blocks of multiple sizes, which can\n",
    "also be merged to obtain a more flexible shape. This is\n",
    "illustrated in the following picture:<br>\n",
    "![Lecture13-3.PNG](Img-Lecture13\\Lecture13-3.PNG)\n",
    "<br>\n",
    "(From: Video Compression Using Nested Quadtree\n",
    "Structures, Leaf Merging, and Improved Techniques\n",
    "for Motion Representation and Entropy Coding, by D. Marpe\n",
    "et al., Transactions on Circuits and Systems for Video\n",
    "Technology, Dec. 2010, [2]).<br>\n",
    "The maximum block size is also increased compared to\n",
    "H.264, to 64x64 pixels. Further we have 32x32, 16x16, 8x16,\n",
    "16x8, 8x8.<br>\n",
    "We also have variable block transform sizes, which don't need\n",
    "to be quadratic, like 16x4, 4x16, or 8x8 pixels.<br><br>\n",
    "The following image shows an example how this flexible\n",
    "blocking structure can be used to adapt it to the image\n",
    "content:<br>\n",
    "\n",
    "![Lecture13-4.PNG](Img-Lecture13\\Lecture13-4.PNG)\n",
    "(From [2])<br>\n",
    "\n",
    "</font></p>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<font size=\"8\" color =\"Brown\"><center>\n",
    "# Improved Intra Prediction  Angular Prediction<center></font>\n",
    "<br>\n",
    " \n",
    "\n",
    "<p style=\"line-height:1.5\">\n",
    "<font size=\"6\">Since we now target videos with higher resolution, we can expect more pixels with similar values (more smooth areas\n",
    "since we have high resolution, and the flexible subdivision for\n",
    "the blocks) and with more redundancies between them. This\n",
    "means we can take advantage of an improved prediction\n",
    "within an image, the intra prediction. If we have some sort of\n",
    "stripe pattern of a certain direction in our image, it makes\n",
    "sense to use directional prediction along those stripes, with\n",
    "the angle of those stripes, as can be seen in the following\n",
    "image:\n",
    "   <br ><br> \n",
    "\n",
    "![Lecture13-5.PNG](Img-Lecture13\\Lecture13-5.PNG)    \n",
    "<br>    \n",
    "(From: High Performance, Low Complexity Video Coding\n",
    "and the Emerging HEVC Standard, Ugur et al., Transactions\n",
    "on Circuits and Systems for Video Technology, Dec. 2010,\n",
    "[3]).<br><br>\n",
    "Here a certain **angle is chosen** (by the encoder), and if\n",
    "necessary the original pixels at the already transmitted\n",
    "boundary regions (in the image the triangular shapes, the\n",
    "pixels from the neighboring blocks) are **interpolated** to\n",
    "obtain a predicted value. The difference to the actual value is\n",
    "then transmitted (after the block transform). In this way we\n",
    "can predict all pixels in our new block.<br>\n",
    "The angles of this prediction are specified from the lowest\n",
    "row of the to be predicted block to the first already received\n",
    "row above, hence **8 pixels above.** In this way we can specify\n",
    "the **angles as integer pixel offsets** (0 or +-n). For angles to\n",
    "the left, the last column of the last received block, to the left,\n",
    "is also used as a reference row, such that we always get the\n",
    "nearest received pixel as a reference.<br>\n",
    "This means if we predict the last row, we don't need\n",
    "interpolation because we have integer pixel positions as\n",
    "reference pixels. But if we predict other pixels, we might\n",
    "need **fractional pixel positions,** as shown in the picture\n",
    "above. In this case we need a suitable **interpolation** to obtain\n",
    "the reference value between the integer pixels. The proposal\n",
    "of Tandberg et al. uses simple linear interpolation. It was\n",
    "found that the gain on coding efficiency using this tool\n",
    "depends on the test set, and varies between 1.5% and 11.2%.\n",
    "The average over the test set was 3.9% (from [3]). In addition\n",
    "to these gains, also a perceptual improvement is obtained, as\n",
    "can be seen in the following picture. <br>\n",
    "\n",
    "![Lecture13-6.PNG](Img-Lecture13\\Lecture13-6.PNG)\n",
    "(From [3])<br>\n",
    "This tools is useful for stripe like patterns. The encoder\n",
    "choses this tool if good prediction performance is found.\n",
    "For more even patterns, the following tool is intended:\n",
    "<br>\n",
    "</font></p>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font size=\"8\" color =\"Brown\"><center>\n",
    "\n",
    "## Planar Coding<center></font>\n",
    "<br>\n",
    "<p style=\"line-height:1.5\">\n",
    "<font size=\"6\">\n",
    "This tool can be used by the encoder if there is no fine pattern\n",
    "in the area to encode. Basically all the encoder sends of this\n",
    "block is the pixel value of the lowest rightmost pixel, and all\n",
    "the other pixels of the block are interpolated starting from the \n",
    "already received pixels to the left and above.<br>\n",
    "In this way we get smooth planar values for our pixels. This\n",
    "process is illustrated in the following picture:\n",
    "    \n",
    "![Lecture13-7.PNG](Img-Lecture13\\Lecture13-7.PNG)    \n",
    "(From: [3])<br>\n",
    "Especially for smooth regions of an image this planar coding\n",
    "also achieves a perceptual improvement, as can be seen on the\n",
    "following picture. Here, especially the **blocking artifacts** are\n",
    "avoided by using planar coding. This is because in the usual\n",
    "DCT coding, we could only transmit the DC coefficient for\n",
    "smooth regions, but this would not allow a non-zero **gradient**\n",
    "along the smooth surface (even with a deblocking filter, as in\n",
    "H.264). This non-zero gradient is possible with this planar \n",
    "coding.    <br><br>\n",
    "![Lecture13-8.PNG](Img-Lecture13\\Lecture13-8.PNG)\n",
    "<br>\n",
    "\n",
    "(From [3]).<br>\n",
    "Observe that in planar mode, **no residual signal is\n",
    "transmitted!**<br>\n",
    "This can also be seen as encoding a smooth region with only\n",
    "1/8th of the pixels along each dimension (**downsampling by a\n",
    "factor of 8** along dimension x and y), or with 1/64th the\n",
    "number of pixels for a 2-dimensional region. This can also be\n",
    "seen as an adaptive sampling rate. This donwsampling can be\n",
    "efficiently done since there are no high spacial frequencies in\n",
    "the smooth region. The decoder then just **upsample** and\n",
    "**interpolates** the region to fit into the reconstructed image.\n",
    "\n",
    "</font></p>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font size=\"8\" color =\"Brown\"><center>\n",
    "## In-Loop Filtering    \n",
    "<center></font>\n",
    "<br>  \n",
    "<p style=\"line-height:1.5\">\n",
    "<font size=\"6\">\n",
    "The proposal by HHI includes a deblocking filter and a \n",
    "subsequent quadtree based separable 2-D Wiener filter.\n",
    "The Wiener filter is applied to reduce additional quantization\n",
    "noise after the deblocking filter.\n",
    "The deblocking filter is a straightforward extension of the one\n",
    "used in H.264 for the HHI proposal. Tandberg proposes a\n",
    "more modified de-blocking filter.</font></p>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"8\" color =\"Brown\"><center>\n",
    "## Spatially Varying Transform<center></font>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"line-height:1.5\">\n",
    "<font size=\"6\">\n",
    "The Tandberg proposal has a spatially varying transform.\n",
    "Here we not only have transform blocks which are identical\n",
    "to the processing blocks, but also the possibility of smaller\n",
    "blocks, and even non-quadratic blocks. Here we also need an\n",
    "offset information, to specify the position of the transform\n",
    "inside the block. This can be seen on the following picture.\n",
    "    <br>\n",
    "    \n",
    "![Lecture13-9.PNG](Img-Lecture13\\Lecture13-9.PNG)\n",
    "\n",
    "<br>\n",
    "    \n",
    "(From [3]).<br>\n",
    "Observe that non-quadratic transform blocks don't mean nonquadratic\n",
    "transform matrices. It just means that the DCT\n",
    "matrix for the rows has a different quadratic size than for the\n",
    "columns, since it is a separable transform. For instance for a\n",
    "4x16 image block, you multiply a 4x4 DCT matrix from the\n",
    "left, and a 16x16 DCT matrix from the right.<br>\n",
    "Also observe that these transform blocks now **don't cover the\n",
    "entire area**, they concentrate on a **part** of it. This is\n",
    "beneficial if most of the information is concentrated in that\n",
    "area. For instance if after motion compensation, a new\n",
    "background becomes visible, this cannot be efficiently \n",
    "predicted and appears as a stripe of high values along edges in\n",
    "an image. In these cases the reduced transform sizes reduce\n",
    "the complexity and also the information needed to be\n",
    "transmitted. The proposal uses transform block sizes of 16x4,\n",
    "4x16, and 8x8.<br>\n",
    "In this way we get some dependency of the transform block\n",
    "shape on the image content. In H.264 we had this dependency\n",
    "only for the transform block size.<br>\n",
    "But it seems this tool did not make it into the final standard.\n",
    "\n",
    "\n",
    "</font></p>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font size=\"8\" color =\"Brown\"><center>\n",
    "## Skip Mode     \n",
    "<center></font>\n",
    "<br>\n",
    "\n",
    "\n",
    "<p style=\"line-height:1.5\">\n",
    "<font size=\"6\">In this mode, almost **no information** is transmitted to the\n",
    "decoder. This is useful for very smooth regions with common\n",
    "movement. For instance for the inner blocks of a moving\n",
    "object. The encoder just signals, which motion vector is to be\n",
    "used (1 of 2 candidates with 1 bit), and the decoder only uses\n",
    "this motion vector to reconstruct the block, without any\n",
    "residual.</font></p>    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"8\" color =\"Brown\"><center>\n",
    "# Improved Fractional Sample Interpolation     \n",
    "<center></font>\n",
    "<br>\n",
    "\n",
    "<p style=\"line-height:1.5\">\n",
    "<font size=\"6\">\n",
    "The proposal from HHI includes an interesting improved **fractional sample interpolation**, which is used for the\n",
    "motion compensation/prediction. We need an interpolation,\n",
    "because usually the reference values are not at integer pixel\n",
    "positions.<br>\n",
    "We had this approach with using a correspondingly increased\n",
    "reference picture. For instance, for a quarter pixel motion \n",
    "accuracy, we need to increase the reference picture size by a\n",
    "factor of 4 along each dimension, x and y. But how do we get\n",
    "precise interpolated values, in between the original pixels?\n",
    "In this case, how do we get those 3 new pixel values for each\n",
    "old pixel along x and y? The simplest way would be to simply\n",
    "repeat the last pixel value, but this usually gives not a good\n",
    "estimate of the real image values. So far we used **bi-linear**\n",
    "interpolation, but it also turns out to be **not precise enough**\n",
    "for many natural images (it can create artificial edges).\n",
    "On the other extreme, to make the interpolation very smooth,\n",
    "we have an **ideal low pass filter**, with which we filter the\n",
    "upsampled image (insert 3 zeros after each pixel along x and\n",
    "y). This would give us very precise image values, if the\n",
    "original image is **band limited** according to Nyquist. But this\n",
    "requirement is also often not realistic, and also the ideal low\n",
    "pass filter would require a sinc impulse response, which is\n",
    "infinitely long, and hence would be very complex to apply.<br>\n",
    "Hence we are looking for a good compromise, with low\n",
    "complexity, but also with good approximation properties. The\n",
    "interpolated values should be as close as possible to the “real”\n",
    "image.</font></p>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"8\" color =\"Brown\"><center>\n",
    "# Video Demo\n",
    "<center></font>\n",
    "<br>\n",
    "\n",
    "\n",
    "<p style=\"line-height:1.5\">\n",
    "<font size=\"6\">\n",
    "Acronyms:\n",
    "CU: **Coding unit**, the blocks for coding.<br>\n",
    "PU: **Prediction unit**, the block for the prediction.<br>\n",
    "TU: **Transform unit**, the blocks for which we apply the\n",
    "transform.<br>\n",
    "-Above right: CU- Partitioning (red: intra, blue: inter, green:\n",
    "skip) with motion vectors.<br>\n",
    "-Lower left: Reference-indices of each PUs (blue: previous\n",
    "frame, orange: second reference frame, green: third reference\n",
    "frame etc.)<br>\n",
    "-Lower right: TU- Partitioning, white lines signal further\n",
    "(finer) sub division of the CU's into sub- TU's.<br>\n",
    "Videos courtesy of Dominic Springer, Lehrstuhl fuer\n",
    "Nachrichtentechnik, University Erlangen-Nuremberg.</font></p>  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
